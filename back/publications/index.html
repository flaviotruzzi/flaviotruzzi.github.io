---
layout: page
title: Publications
---

<header>
    <hgroup>
        <h2>{{page.title}}</h2>
    </hgroup>
</header>

<p>Check my <a href="https://github.com/flaviotruzzi?tab=repositories">GitHub repositories</a> for my last projects.</p>

<p>Here are selected publications:</p>

<div class="proj-item">
	<h3><a href="http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=6726452">Ad Network Optimization: Evaluating Linear Relaxations</a></h3>
	<div class="proj-details">
		<p>This paper presents a theoretical and empirical analysis of linear programming relaxations to ad network optimization. The underlying problem is to select a sequence of ads to send to websites, while an optimal policy can be produced using a Markov Decision Process, in practice one must resort to relaxations to bypass the curse of dimensionality. We focus on a state-of-art relaxation scheme based on linear programming. We build a Markov Decision Process that captures the worst-case behavior of such a linear programming relaxation, and derive theoretical guarantees concerning linear relaxations. We then report on extensive empirical evaluation of linear relaxations, our results suggest that for large problems (similar to ones found in practice), the loss of performance introduced by linear relaxations is rather small.</p>
	</div>
</div>

<div class="proj-item">
    <h3><a href="http://sites.poli.usp.br/p/fabio.cozman/Publications/Article/truzzi-silva-costa-cozman-eniac2013.pdf‎">AdBandit: A New Algorithm For Multi-Armed Bandits.</a></h3>
    <div class="proj-details">
        <p>In this paper we present a new algorithm for the finite-horizon stochastic multi-armed bandit problem with Bernoulli rewards called AdBandits. It is based upon two previous algorithms the Thompson Sampling and the UCB-Bayes associated with a minimax exploitation method. We report the results of this new algorithm comparing it with classical solutions to the multi-armed bandit such as: UCB, UCB-Bayes and Thompson Sampling.</p>
    </div>
</div>

<div class="proj-item">
    <h3><a href="http://sites.poli.usp.br/p/fabio.../truzzi-silva-costa-cozman-enia2012F.pdf‎">Markov Decision Processes for Ad Network Optimization</a></h3>
    <div class="proj-details">
        <p>In this paper we examine a central problem in a particular advertising scheme: we are concerned with matching marketing campaigns that produce advertisements (“ads”), to impressions — where “impression” is a general term for any space in the internet that can display an ad. In this paper we propose a new take on the problem by resorting to planning techniques based on Markov Decision Processes, and by resorting to plan generation techniques that have been developed in the AI literature. We present a detailed formulation of the Markov Decision Process approach and results of simulated experiments.</p>
    </div>
</div>
